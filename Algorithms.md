# ► Algorithms

## ▷ Text-to-Speech (TTS)

* ⭐ **[Tacotron](https://arxiv.org/abs/1703.10135)** - An end-to-end neural network architecture for TTS that generates mel-spectrograms from text.
* ⭐ **[WaveNet](https://arxiv.org/abs/1609.03499)** - A deep generative model for generating raw audio waveforms, known for its high-quality audio synthesis.
* ⭐ **[FastSpeech](https://arxiv.org/abs/1905.09263)** - A speech synthesis model designed to improve speed and quality over Tacotron.

## ▷ Speech-to-Text (STT)

* ⭐ **[CTC (Connectionist Temporal Classification)](https://arxiv.org/abs/ Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks)** - An algorithm for sequence-to-sequence tasks, often used in STT models to handle variable-length input sequences.
* ⭐ **[Attention Mechanism](https://arxiv.org/abs/1409.0473)** - A technique used in neural networks to focus on different parts of the input sequence, improving performance in STT models.
* ⭐ **[Transformer](https://arxiv.org/abs/1706.03762)** - A model architecture based on self-attention mechanisms, widely used in modern STT systems for its efficiency and scalability.

## ▷ General AI Algorithms

* ⭐ **[Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)** - An optimization algorithm used to minimize the loss function in training machine learning models.
* ⭐ **[Random Forest](https://en.wikipedia.org/wiki/Random_forest)** - An ensemble learning method for classification and regression, based on constructing multiple decision trees.
* ⭐ **[K-means Clustering](https://en.wikipedia.org/wiki/K-means_clustering)** - An unsupervised learning algorithm for partitioning data into clusters based on similarity.

